import streamlit as st
import feedparser
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os
import html
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="êµ­ë‚´ ë‰´ìŠ¤ RSS í”¼ë“œ", page_icon="ğŸ“°")

# RSS í”¼ë“œ URL ëª©ë¡ (êµ­ë‚´ ë‰´ìŠ¤)
RSS_FEEDS = {
    'í•œê²¨ë ˆ': 'https://www.hani.co.kr/rss/',
    'ê²½í–¥ì‹ ë¬¸': 'https://www.khan.co.kr/rss/rssdata/total_news.xml',
    'ì¡°ì„ ì¼ë³´': 'http://news.chosun.com/site/data/rss/rss.xml',
    'ì—°í•©ë‰´ìŠ¤': 'https://www.yna.co.kr/rss/all',
    'ë™ì•„ì¼ë³´': 'https://rss.donga.com/total.xml',
    'KBS ë‰´ìŠ¤': 'http://world.kbs.co.kr/rss/rss_news.htm?lang=k',
    'MBC ë‰´ìŠ¤': 'https://imnews.imbc.com/rss/news/news_00.xml',
    'SBS ë‰´ìŠ¤': 'https://news.sbs.co.kr/news/SectionRssFeed.do?sectionId=01',
}

def fetch_news(feed_url):
    feed = feedparser.parse(feed_url)
    news_items = []
    for entry in feed.entries:
        title = html.unescape(entry.title)
        summary = html.unescape(entry.summary)
        summary = re.sub('<[^<]+?>', '', summary)  # HTML íƒœê·¸ ì œê±°
        news_items.append({"title": title, "link": entry.link, "summary": summary})
    return news_items

def generate_wordcloud(text):
    # í°íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    font_path = os.path.join(os.path.dirname(__file__), 'NanumGothic.ttf')
    
    # í°íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(font_path):
        st.error(f"í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
        return
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    wordcloud = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(text)
    
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    
    # Streamlitì— ê·¸ë¦¬ê¸°
    st.pyplot(plt)

# Streamlit ì•± ì½”ë“œ
st.title("êµ­ë‚´ ë‰´ìŠ¤ RSS í”¼ë“œ")

# ê´€ì‹¬ ìˆëŠ” ì£¼ì œ ë° í‚¤ì›Œë“œ ì…ë ¥
keyword = st.text_input("ê´€ì‹¬ ìˆëŠ” ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "ë¶í•œ")
num_news = st.slider("ë³´ì—¬ì¤„ ë‰´ìŠ¤ ê°œìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:", 1, 20, 10)

if st.button("ë‰´ìŠ¤ ë³´ê¸°"):
    news_data = []
    for source, url in RSS_FEEDS.items():
        news_items = fetch_news(url)
        for item in news_items:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ í‚¤ì›Œë“œ ë¹„êµ
            if keyword.lower() in item['title'].lower():
                news_data.append(item)
    
    # ì„ íƒí•œ ë‰´ìŠ¤ ê°œìˆ˜ë§Œí¼ ì¶œë ¥
    if len(news_data) > num_news:
        news_data = news_data[:num_news]
    
    # ì¶œë ¥ëœ ë‰´ìŠ¤ í‘œì‹œ
    if news_data:
        for news in news_data:
            st.subheader(news['title'])
            st.write(news['summary'])
            st.write(f"[ë§í¬ë¡œ ì´ë™]({news['link']})")

        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        all_titles = ' '.join(item['title'] for item in news_data)
        generate_wordcloud(all_titles)
    else:
        st.write("í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
